# HÆ°á»›ng dáº«n cÃ i Ä‘áº·t chi tiáº¿t Kubernetes Cluster

## ğŸ“‹ Má»¥c lá»¥c

1. [Chuáº©n bá»‹ mÃ´i trÆ°á»ng](#chuáº©n-bá»‹-mÃ´i-trÆ°á»ng)
2. [Cáº¥u hÃ¬nh inventory](#cáº¥u-hÃ¬nh-inventory)
3. [CÃ i Ä‘áº·t cluster cÆ¡ báº£n](#cÃ i-Ä‘áº·t-cluster-cÆ¡-báº£n)
4. [CÃ i Ä‘áº·t monitoring stack](#cÃ i-Ä‘áº·t-monitoring-stack)
5. [CÃ i Ä‘áº·t Rancher (tÃ¹y chá»n)](#cÃ i-Ä‘áº·t-rancher-tÃ¹y-chá»n)
6. [XÃ¡c minh cÃ i Ä‘áº·t](#xÃ¡c-minh-cÃ i-Ä‘áº·t)
7. [Troubleshooting](#troubleshooting)

## ğŸ”§ Chuáº©n bá»‹ mÃ´i trÆ°á»ng

### YÃªu cáº§u há»‡ thá»‘ng

#### Master Node
- **CPU**: Tá»‘i thiá»ƒu 2 cores, khuyáº¿n nghá»‹ 4 cores
- **RAM**: Tá»‘i thiá»ƒu 4GB, khuyáº¿n nghá»‹ 8GB
- **Disk**: Tá»‘i thiá»ƒu 50GB, khuyáº¿n nghá»‹ 100GB SSD
- **Network**: 1Gbps ethernet

#### Worker Nodes
- **CPU**: Tá»‘i thiá»ƒu 2 cores, khuyáº¿n nghá»‹ 4 cores
- **RAM**: Tá»‘i thiá»ƒu 4GB, khuyáº¿n nghá»‹ 16GB
- **Disk**: Tá»‘i thiá»ƒu 50GB, khuyáº¿n nghá»‹ 200GB SSD
- **Network**: 1Gbps ethernet

### CÃ i Ä‘áº·t dependencies

#### TrÃªn mÃ¡y control (mÃ¡y cháº¡y Ansible)

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install -y python3 python3-pip git ansible

# CentOS/RHEL
sudo yum install -y python3 python3-pip git ansible

# CÃ i Ä‘áº·t Python packages
pip3 install --user ansible netaddr jinja2 ruamel.yaml cryptography
```

#### TrÃªn táº¥t cáº£ nodes

```bash
# Disable swap
sudo swapoff -a
sudo sed -i '/ swap / s/^/#/' /etc/fstab

# Cáº¥u hÃ¬nh kernel modules
cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
br_netfilter
ip_vs
ip_vs_rr
ip_vs_wrr
ip_vs_sh
nf_conntrack
EOF

# Load modules
sudo modprobe br_netfilter
sudo modprobe ip_vs
sudo modprobe ip_vs_rr
sudo modprobe ip_vs_wrr
sudo modprobe ip_vs_sh
sudo modprobe nf_conntrack

# Cáº¥u hÃ¬nh sysctl
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
net.ipv4.ip_forward = 1
EOF

sudo sysctl --system
```

### Cáº¥u hÃ¬nh SSH

```bash
# Táº¡o SSH key (náº¿u chÆ°a cÃ³)
ssh-keygen -t rsa -b 4096 -C "your-email@domain.com"

# Copy SSH key Ä‘áº¿n táº¥t cáº£ nodes
ssh-copy-id user@master-ip
ssh-copy-id user@worker1-ip
ssh-copy-id user@worker2-ip

# Test SSH connectivity
ssh user@master-ip "sudo whoami"
ssh user@worker1-ip "sudo whoami"
ssh user@worker2-ip "sudo whoami"
```

## ğŸ“ Cáº¥u hÃ¬nh inventory

### Táº¡o inventory file

Chá»‰nh sá»­a `inventory/hosts.yml`:

```yaml
all:
  hosts:
    # Master node
    k8s-master:
      ansible_host: 192.168.1.10
      ip: 192.168.1.10
      access_ip: 192.168.1.10
      ansible_user: ubuntu
      ansible_ssh_private_key_file: ~/.ssh/id_rsa
    
    # Worker nodes
    k8s-worker1:
      ansible_host: 192.168.1.11
      ip: 192.168.1.11
      access_ip: 192.168.1.11
      ansible_user: ubuntu
      ansible_ssh_private_key_file: ~/.ssh/id_rsa
    
    k8s-worker2:
      ansible_host: 192.168.1.12
      ip: 192.168.1.12
      access_ip: 192.168.1.12
      ansible_user: ubuntu
      ansible_ssh_private_key_file: ~/.ssh/id_rsa

  children:
    kube_control_plane:
      hosts:
        k8s-master:
    
    kube_node:
      hosts:
        k8s-worker1:
        k8s-worker2:
    
    etcd:
      hosts:
        k8s-master:
    
    k8s_cluster:
      children:
        kube_control_plane:
        kube_node:
    
    calico_rr:
      hosts: {}
```

### Kiá»ƒm tra connectivity

```bash
# Test Ansible connectivity
ansible all -i inventory/hosts.yml -m ping

# Kiá»ƒm tra sudo access
ansible all -i inventory/hosts.yml -m shell -a "sudo whoami" -b
```

## ğŸš€ CÃ i Ä‘áº·t cluster cÆ¡ báº£n

### Option 1: Sá»­ dá»¥ng script tá»± Ä‘á»™ng

```bash
# CÃ i Ä‘áº·t cluster cÆ¡ báº£n
./install.sh

# Hoáº·c vá»›i cÃ¡c tÃ¹y chá»n
./install.sh --help
```

### Option 2: CÃ i Ä‘áº·t tá»«ng bÆ°á»›c

#### BÆ°á»›c 1: Pre-installation

```bash
./scripts/pre-install.sh
```

Script nÃ y sáº½:
- Kiá»ƒm tra system requirements
- Cáº¥u hÃ¬nh SSH keys
- CÃ i Ä‘áº·t dependencies
- Chuáº©n bá»‹ kubespray

#### BÆ°á»›c 2: Cháº¡y kubespray

```bash
./scripts/install-kubespray.sh
```

QuÃ¡ trÃ¬nh nÃ y cÃ³ thá»ƒ máº¥t 15-30 phÃºt tÃ¹y thuá»™c vÃ o:
- Tá»‘c Ä‘á»™ máº¡ng
- Hiá»‡u nÄƒng hardware
- Sá»‘ lÆ°á»£ng nodes

#### BÆ°á»›c 3: Post-installation

```bash
./scripts/post-install.sh
```

Script nÃ y sáº½:
- Cáº¥u hÃ¬nh kubectl
- CÃ i Ä‘áº·t Helm
- Thiáº¿t láº­p storage classes
- Cáº¥u hÃ¬nh network policies

### XÃ¡c minh cÃ i Ä‘áº·t cÆ¡ báº£n

```bash
# Kiá»ƒm tra nodes
kubectl get nodes -o wide

# Kiá»ƒm tra system pods
kubectl get pods -n kube-system

# Kiá»ƒm tra cluster info
kubectl cluster-info

# Test táº¡o pod
kubectl run test-pod --image=nginx --rm -it --restart=Never -- curl -I http://kubernetes.default.svc.cluster.local
```

## ğŸ“Š CÃ i Ä‘áº·t monitoring stack

### CÃ i Ä‘áº·t tá»± Ä‘á»™ng

```bash
# CÃ i Ä‘áº·t complete monitoring stack
./scripts/install-complete-monitoring.sh

# Hoáº·c tá»«ng component
./scripts/install-monitoring-stack.sh
```

### CÃ i Ä‘áº·t thá»§ cÃ´ng

#### BÆ°á»›c 1: Táº¡o namespace

```bash
kubectl create namespace monitoring
```

#### BÆ°á»›c 2: CÃ i Ä‘áº·t Prometheus

```bash
# Add Prometheus Helm repo
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

# Install Prometheus
helm install prometheus prometheus-community/kube-prometheus-stack \
  --namespace monitoring \
  --values manifests/monitoring/prometheus-values.yaml
```

#### BÆ°á»›c 3: CÃ i Ä‘áº·t Grafana

```bash
# Grafana Ä‘Ã£ Ä‘Æ°á»£c cÃ i cÃ¹ng vá»›i Prometheus stack
# Cáº¥u hÃ¬nh dashboards
kubectl apply -f manifests/monitoring/grafana-dashboards-config.yaml
```

#### BÆ°á»›c 4: CÃ i Ä‘áº·t Loki

```bash
# Add Grafana Helm repo
helm repo add grafana https://grafana.github.io/helm-charts
helm repo update

# Install Loki
helm install loki grafana/loki-stack \
  --namespace monitoring \
  --values manifests/monitoring/loki-values.yaml
```

#### BÆ°á»›c 5: Cáº¥u hÃ¬nh Ingress

```bash
# CÃ i Ä‘áº·t NGINX Ingress Controller
./scripts/install-ingress.sh

# Apply ingress rules
kubectl apply -f manifests/monitoring/prometheus-ingress.yaml
kubectl apply -f manifests/monitoring/grafana-ingress.yaml
kubectl apply -f manifests/monitoring/alertmanager-ingress.yaml
```

### Truy cáº­p monitoring services

#### Grafana

```bash
# Láº¥y admin password
kubectl get secret --namespace monitoring grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo

# Port forward (náº¿u chÆ°a cÃ³ ingress)
kubectl port-forward --namespace monitoring svc/grafana 3000:80
```

Truy cáº­p: http://localhost:3000
- Username: admin
- Password: tá»« lá»‡nh trÃªn

#### Prometheus

```bash
# Port forward
kubectl port-forward --namespace monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090
```

Truy cáº­p: http://localhost:9090

#### AlertManager

```bash
# Port forward
kubectl port-forward --namespace monitoring svc/prometheus-kube-prometheus-alertmanager 9093:9093
```

Truy cáº­p: http://localhost:9093

## ğŸ›ï¸ CÃ i Ä‘áº·t Rancher (tÃ¹y chá»n)

### CÃ i Ä‘áº·t tá»± Ä‘á»™ng

```bash
./scripts/install-rancher-complete.sh
```

### CÃ i Ä‘áº·t thá»§ cÃ´ng

#### BÆ°á»›c 1: CÃ i Ä‘áº·t cert-manager

```bash
./scripts/install-cert-manager.sh
```

#### BÆ°á»›c 2: CÃ i Ä‘áº·t Rancher

```bash
# Add Rancher Helm repo
helm repo add rancher-stable https://releases.rancher.com/server-charts/stable
helm repo update

# Create namespace
kubectl create namespace cattle-system

# Install Rancher
helm install rancher rancher-stable/rancher \
  --namespace cattle-system \
  --set hostname=rancher.your-domain.com \
  --set bootstrapPassword=admin123456 \
  --set ingress.tls.source=letsEncrypt \
  --set letsEncrypt.email=your-email@domain.com
```

#### BÆ°á»›c 3: Truy cáº­p Rancher

```bash
# Kiá»ƒm tra tráº¡ng thÃ¡i
kubectl -n cattle-system rollout status deploy/rancher

# Láº¥y URL
echo "https://rancher.your-domain.com"
```

## âœ… XÃ¡c minh cÃ i Ä‘áº·t

### Kiá»ƒm tra tá»•ng quan

```bash
# Cháº¡y script kiá»ƒm tra
./scripts/check-monitoring-stack.sh
```

### Kiá»ƒm tra tá»«ng component

```bash
# Nodes
kubectl get nodes -o wide

# Pods trong táº¥t cáº£ namespaces
kubectl get pods --all-namespaces

# Services
kubectl get svc --all-namespaces

# Ingress
kubectl get ingress --all-namespaces

# Storage classes
kubectl get storageclass

# Persistent volumes
kubectl get pv,pvc --all-namespaces
```

### Test workload

```bash
# Deploy test application
kubectl create deployment nginx-test --image=nginx
kubectl expose deployment nginx-test --port=80 --type=ClusterIP

# Test service discovery
kubectl run test-pod --image=busybox --rm -it --restart=Never -- nslookup nginx-test

# Cleanup
kubectl delete deployment nginx-test
kubectl delete service nginx-test
```

## ğŸ”§ Troubleshooting

### Lá»—i thÆ°á»ng gáº·p

#### 1. Nodes NotReady

```bash
# Kiá»ƒm tra node status
kubectl describe node <node-name>

# Kiá»ƒm tra kubelet logs
sudo journalctl -u kubelet -f

# Restart kubelet
sudo systemctl restart kubelet
```

#### 2. Pods Pending/CrashLoopBackOff

```bash
# Kiá»ƒm tra pod details
kubectl describe pod <pod-name> -n <namespace>

# Xem logs
kubectl logs <pod-name> -n <namespace> --previous

# Kiá»ƒm tra resources
kubectl top nodes
kubectl top pods --all-namespaces
```

#### 3. Network issues

```bash
# Kiá»ƒm tra Calico pods
kubectl get pods -n kube-system | grep calico

# Test pod-to-pod connectivity
kubectl run test1 --image=busybox --rm -it --restart=Never -- ping <pod-ip>

# Kiá»ƒm tra DNS
kubectl run test-dns --image=busybox --rm -it --restart=Never -- nslookup kubernetes.default
```

#### 4. Storage issues

```bash
# Kiá»ƒm tra storage classes
kubectl get storageclass

# Kiá»ƒm tra PV/PVC
kubectl get pv,pvc --all-namespaces

# Describe PVC Ä‘á»ƒ xem lá»—i
kubectl describe pvc <pvc-name> -n <namespace>
```

### Debug commands

```bash
# Cluster info
kubectl cluster-info dump

# Events
kubectl get events --sort-by=.metadata.creationTimestamp

# Resource usage
kubectl top nodes
kubectl top pods --all-namespaces

# API server logs
sudo journalctl -u kube-apiserver -f

# Controller manager logs
sudo journalctl -u kube-controller-manager -f

# Scheduler logs
sudo journalctl -u kube-scheduler -f
```

### Logs locations

```bash
# Kubelet logs
sudo journalctl -u kubelet -f

# Container runtime logs (containerd)
sudo journalctl -u containerd -f

# Kubernetes audit logs
sudo tail -f /var/log/audit.log

# Application logs
kubectl logs -f <pod-name> -n <namespace>
```

## ğŸ“ Há»— trá»£

Náº¿u gáº·p váº¥n Ä‘á» trong quÃ¡ trÃ¬nh cÃ i Ä‘áº·t:

1. Kiá»ƒm tra [troubleshooting guide](troubleshooting.md)
2. Xem [GitHub Issues](https://github.com/ddphuc01/k8s-cluster-setup/issues)
3. Táº¡o issue má»›i vá»›i Ä‘áº§y Ä‘á»§ thÃ´ng tin:
   - OS version
   - Hardware specs
   - Error logs
   - Steps to reproduce

---

**ChÃºc báº¡n cÃ i Ä‘áº·t thÃ nh cÃ´ng! ğŸ‰**
